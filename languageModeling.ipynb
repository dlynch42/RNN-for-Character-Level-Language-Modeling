{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files with terminal link\n",
    "# curl https://www.gutenberg.org/cache/epub/2265/pg2265.txt > pg2265.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into python session as plain text \n",
    "# Chars represent set of unique characters\n",
    "# Reads text, removes beginning portion of legal description, constructs dictionaries based on text\n",
    "import numpy as np\n",
    "# Read and process text\n",
    "with open('pg2265.txt', 'r', encoding='utf-8') as f:\n",
    "    text=f.read()\n",
    "text = text[15858:]\n",
    "chars = set(text)\n",
    "char2int = {ch:i for i, ch in enumerate(chars)}\n",
    "int2char = dict(enumerate(chars))\n",
    "text_ints = np.array([char2int[ch] for ch in text], \n",
    "                        dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape into batches of sequences\n",
    "# Shift input (x) and output (y) of neural network by one character\n",
    "def reshape_data(sequence, batch_size, num_steps):\n",
    "    mini_batch_length = batch_size * num_steps\n",
    "    num_batches = int(len(sequence) / mini_batch_length)\n",
    "    if num_batches*mini_batch_length + 1 > len(sequence):\n",
    "        num_batches = num_batches - 1\n",
    "    \n",
    "    # Truncate sequence at end to get rid of remaining characters that don't make full batch\n",
    "    x = sequence[0: num_batches*mini_batch_length]\n",
    "    y = sequence[1: num_batches*mini_batch_length + 1]\n",
    "\n",
    "    # Split x and y into list batches of sequences\n",
    "    x_batch_splits = np.split(x, batch_size)\n",
    "    y_batch_splits = np.split(y, batch_size)\n",
    "\n",
    "    # Stack batches together; batch_size x mini_batch_length\n",
    "    x = np.stack(x_batch_splits)\n",
    "    y = np.stack(y_batch_splits)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch generator\n",
    "# Split arrays x and y into mini-batches where row is seq w/ len = steps\n",
    "def create_batch_generator(data_x, data_y, num_steps):\n",
    "    batch_size, tot_batch_length = data_x.shape\n",
    "    num_batches = int(tot_batch_length/num_steps)\n",
    "    for b in range(num_batches):\n",
    "        yield (data_x[:, b*num_steps: (b+1)*num_steps],\n",
    "               data_y[:, b*num_steps: (b+1)*num_steps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement class \n",
    "# Constructs graph of RNN to predict next character after observing sequence of characters\n",
    "import tensorflow._api.v2.compat.v1 as tf\n",
    "import os\n",
    "\n",
    "# Helper fxn: get_top_char method\n",
    "def get_top_char(probas, char_size, top_n=5):\n",
    "    p = np.squeeze(probas)\n",
    "    p[np.argsort(p)[:-top_n]] = 0.0\n",
    "    p = p / np.sum(p)\n",
    "    ch_id = np.random.choice(char_size, 1, p=p)[0]\n",
    "    return ch_id\n",
    "\n",
    "class CharRNN(object):\n",
    "    def __init__(self, num_classes, batch_size=64,\n",
    "                 num_steps=100, lstm_size=128,\n",
    "                 num_layers=1, learning_rate=0.001,\n",
    "                 keep_prob=0.5, grad_clip=5,\n",
    "                 sampling=False):\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.num_steps = num_steps\n",
    "        self.lstm_size = lstm_size\n",
    "        self.num_layers = num_layers\n",
    "        self.learning_rate = learning_rate\n",
    "        self.keep_prob = keep_prob\n",
    "        self.grad_clip = grad_clip\n",
    "        # Keep sampling boolean to determine whether instance is \n",
    "        # training (false) or sampling (true)\n",
    "        \n",
    "        self.g = tf.Graph()\n",
    "        with self.g.as_default():\n",
    "            tf.set_random_seed(123)\n",
    "\n",
    "            self.build(sampling=sampling)\n",
    "\n",
    "            self.saver = tf.train.Saver()\n",
    "\n",
    "            self.init_op = tf.global_variables_initializer()\n",
    "        \n",
    "    # Build method doesn't use embedding layer to create salient representation for unique words\n",
    "    # If sampling (testing), batch size = 1; training batch size = batch size\n",
    "    # Uses one-hot encoding\n",
    "    def build(self, sampling):\n",
    "        if sampling == True:\n",
    "            batch_size, num_steps = 1, 1\n",
    "        else:\n",
    "            batch_size = self.batch_size\n",
    "            num_steps = self.num_steps\n",
    "\n",
    "        tf_x = tf.placeholder(tf.int32,\n",
    "                                shape=[batch_size, num_steps],\n",
    "                                name='tf_x')\n",
    "        tf_y = tf.placeholder(tf.int32,\n",
    "                                shape=[batch_size, num_steps],\n",
    "                                name='tf_y')\n",
    "        tf_keepprob = tf.placeholder(tf.float32,\n",
    "                                name='tf_keepprob')\n",
    "\n",
    "        # One-hot encoding:\n",
    "        x_onehot = tf.one_hot(tf_x, depth=self.num_classes)\n",
    "        y_onehot = tf.one_hot(tf_y, depth=self.num_classes)\n",
    "\n",
    "        # Build the multi-layer RNN cells\n",
    "        cells = tf.compat.v1.nn.rnn_cell.MultiRNNCell(\n",
    "                [tf.compat.v1.nn.rnn_cell.DropoutWrapper(\n",
    "                    tf.compat.v1.nn.rnn_cell.BasicLSTMCell(self.lstm_size),\n",
    "                output_keep_prob=tf_keepprob)\n",
    "            for _ in range(self.num_layers)])\n",
    "\n",
    "        # Define the initial state\n",
    "        self.initial_state = cells.zero_state(\n",
    "                    batch_size, tf.float32)\n",
    "\n",
    "        # Run each sequence step through the RNN\n",
    "        lstm_outputs, self.final_state = tf.nn.dynamic_rnn(\n",
    "                    cells, x_onehot,\n",
    "                    initial_state=self.initial_state)\n",
    "\n",
    "        print('  << lstm_outputs  >>', lstm_outputs)\n",
    "\n",
    "        seq_output_reshaped = tf.reshape(\n",
    "                    lstm_outputs,\n",
    "                    shape=[-1, self.lstm_size],\n",
    "                       name='seq_output_reshaped')\n",
    "\n",
    "        logits = tf.layers.dense(\n",
    "                    inputs=seq_output_reshaped,\n",
    "                    units=self.num_classes,\n",
    "                    activation=None,\n",
    "                    name='logits')\n",
    "\n",
    "        proba = tf.nn.softmax(\n",
    "                    logits,\n",
    "                    name='probabilities')\n",
    "\n",
    "        y_reshaped = tf.reshape(\n",
    "                    y_onehot,\n",
    "                    shape=[-1, self.num_classes],\n",
    "                    name='y_reshaped')\n",
    "        cost = tf.reduce_mean(\n",
    "                    tf.nn.softmax_cross_entropy_with_logits(\n",
    "                        logits=logits,\n",
    "                        labels=y_reshaped),\n",
    "                    name='cost')\n",
    "\n",
    "        # Gradient clipping to avoid \"exploding gradients\"\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(\n",
    "                    tf.gradients(cost, tvars),\n",
    "                    self.grad_clip)\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        train_op = optimizer.apply_gradients(\n",
    "                    zip(grads, tvars),\n",
    "                    name='train_op')\n",
    "        \n",
    "    # Train Method\n",
    "    def train(self, train_x, train_y,\n",
    "                 num_epochs, ckpt_dir='./model/'):\n",
    "        # Create the checkpoint directory\n",
    "        # if it does not exists\n",
    "        if not os.path.exists(ckpt_dir):\n",
    "            os.mkdir(ckpt_dir)\n",
    "\n",
    "        with tf.Session(graph=self.g) as sess:\n",
    "            sess.run(self.init_op)\n",
    "\n",
    "            n_batches = int(train_x.shape[1]/self.num_steps)\n",
    "            iterations = n_batches * num_epochs\n",
    "            for epoch in range(num_epochs):\n",
    "                # Train network\n",
    "                new_state = sess.run(self.initial_state)\n",
    "                loss = 0\n",
    "\n",
    "                # Mini-batch generator:\n",
    "                bgen = create_batch_generator(\n",
    "                        train_x, train_y, self.num_steps)\n",
    "                for b, (batch_x, batch_y) in enumerate(bgen, 1):\n",
    "                    iteration = epoch*n_batches + b\n",
    "\n",
    "                    feed = {'tf_x:0': batch_x,\n",
    "                            'tf_y:0': batch_y,\n",
    "                            'tf_keepprob:0' : self.keep_prob,\n",
    "                            self.initial_state : new_state}\n",
    "                    batch_cost, _, new_state = sess.run(\n",
    "                            ['cost:0', 'train_op',\n",
    "                                self.final_state],\n",
    "                            feed_dict=feed)\n",
    "                    if iteration % 10 == 0:\n",
    "                        print('Epoch %d/%d Iteration %d'\n",
    "                            '| Training loss: %.4f' % (\n",
    "                            epoch + 1, num_epochs,\n",
    "                            iteration, batch_cost))\n",
    "\n",
    "                # Save the trained model\n",
    "                self.saver.save(\n",
    "                        sess, os.path.join(\n",
    "                            ckpt_dir, 'language_modeling.ckpt'))\n",
    "    \n",
    "    # Sample Method\n",
    "    # Similar to predict method\n",
    "    def sample(self, output_length,\n",
    "                  ckpt_dir, starter_seq=\"The \"):\n",
    "        observed_seq = [ch for ch in starter_seq]\n",
    "        with tf.Session(graph=self.g) as sess:\n",
    "            self.saver.restore(\n",
    "                sess,\n",
    "                tf.train.latest_checkpoint(ckpt_dir))\n",
    "\n",
    "            # 1: run the model using the starter sequence\n",
    "            new_state = sess.run(self.initial_state)\n",
    "            for ch in starter_seq:\n",
    "                x = np.zeros((1, 1))\n",
    "                x[0, 0] = char2int[ch]\n",
    "                feed = {'tf_x:0': x,\n",
    "                        'tf_keepprob:0': 1.0,\n",
    "                        self.initial_state: new_state}\n",
    "                proba, new_state = sess.run(\n",
    "                        ['probabilities:0', self.final_state],\n",
    "                        feed_dict=feed)\n",
    "\n",
    "            ch_id = get_top_char(proba, len(chars))\n",
    "            observed_seq.append(int2char[ch_id])\n",
    "\n",
    "            # 2: run the model using the updated observed_seq\n",
    "            for i in range(output_length):\n",
    "                x[0,0] = ch_id\n",
    "                feed = {'tf_x:0': x,\n",
    "                        'tf_keepprob:0': 1.0,\n",
    "                        self.initial_state: new_state}\n",
    "                proba, new_state = sess.run(\n",
    "                        ['probabilities:0', self.final_state],\n",
    "                        feed_dict=feed)\n",
    "                        \n",
    "                ch_id = get_top_char(proba, len(chars))\n",
    "                observed_seq.append(int2char[ch_id])\n",
    "\n",
    "        return ''.join(observed_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /var/folders/yr/41cc5dm96jxdwsjd0d6n6yhw0000gn/T/ipykernel_2045/143551028.py:76: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Users/devinlynch/MLBook/.venv/lib/python3.10/site-packages/keras/layers/rnn/legacy_cells.py:726: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "  << lstm_outputs  >> Tensor(\"rnn/transpose_1:0\", shape=(64, 100, 128), dtype=float32)\n",
      "WARNING:tensorflow:From /Users/devinlynch/MLBook/.venv/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1082: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yr/41cc5dm96jxdwsjd0d6n6yhw0000gn/T/ipykernel_2045/143551028.py:67: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  tf.compat.v1.nn.rnn_cell.BasicLSTMCell(self.lstm_size),\n",
      "/var/folders/yr/41cc5dm96jxdwsjd0d6n6yhw0000gn/T/ipykernel_2045/143551028.py:87: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  logits = tf.layers.dense(\n",
      "2022-08-23 17:23:29.097353: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-23 17:23:29.105621: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 Iteration 10| Training loss: 3.7651\n",
      "Epoch 1/100 Iteration 20| Training loss: 3.3743\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 2/100 Iteration 30| Training loss: 3.3098\n",
      "Epoch 2/100 Iteration 40| Training loss: 3.2421\n",
      "Epoch 2/100 Iteration 50| Training loss: 3.2602\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 3/100 Iteration 60| Training loss: 3.2013\n",
      "Epoch 3/100 Iteration 70| Training loss: 3.2051\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 4/100 Iteration 80| Training loss: 3.1940\n",
      "Epoch 4/100 Iteration 90| Training loss: 3.1502\n",
      "Epoch 4/100 Iteration 100| Training loss: 3.1717\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 5/100 Iteration 110| Training loss: 3.1314\n",
      "Epoch 5/100 Iteration 120| Training loss: 3.1145\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 6/100 Iteration 130| Training loss: 3.0959\n",
      "Epoch 6/100 Iteration 140| Training loss: 3.0374\n",
      "Epoch 6/100 Iteration 150| Training loss: 3.0383\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 7/100 Iteration 160| Training loss: 2.9800\n",
      "Epoch 7/100 Iteration 170| Training loss: 2.9638\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 8/100 Iteration 180| Training loss: 2.9233\n",
      "Epoch 8/100 Iteration 190| Training loss: 2.8603\n",
      "Epoch 8/100 Iteration 200| Training loss: 2.8534\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 9/100 Iteration 210| Training loss: 2.7868\n",
      "Epoch 9/100 Iteration 220| Training loss: 2.7916\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 10/100 Iteration 230| Training loss: 2.7368\n",
      "Epoch 10/100 Iteration 240| Training loss: 2.6876\n",
      "Epoch 10/100 Iteration 250| Training loss: 2.6780\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 11/100 Iteration 260| Training loss: 2.6263\n",
      "Epoch 11/100 Iteration 270| Training loss: 2.6410\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 12/100 Iteration 280| Training loss: 2.5884\n",
      "Epoch 12/100 Iteration 290| Training loss: 2.5457\n",
      "Epoch 12/100 Iteration 300| Training loss: 2.5550\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 13/100 Iteration 310| Training loss: 2.5077\n",
      "Epoch 13/100 Iteration 320| Training loss: 2.5262\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 14/100 Iteration 330| Training loss: 2.4956\n",
      "Epoch 14/100 Iteration 340| Training loss: 2.4617\n",
      "Epoch 14/100 Iteration 350| Training loss: 2.4701\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 15/100 Iteration 360| Training loss: 2.4296\n",
      "Epoch 15/100 Iteration 370| Training loss: 2.4718\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 16/100 Iteration 380| Training loss: 2.4219\n",
      "Epoch 16/100 Iteration 390| Training loss: 2.4030\n",
      "Epoch 16/100 Iteration 400| Training loss: 2.4115\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 17/100 Iteration 410| Training loss: 2.3767\n",
      "Epoch 17/100 Iteration 420| Training loss: 2.4120\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 18/100 Iteration 430| Training loss: 2.3731\n",
      "Epoch 18/100 Iteration 440| Training loss: 2.3580\n",
      "Epoch 18/100 Iteration 450| Training loss: 2.3729\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 19/100 Iteration 460| Training loss: 2.3317\n",
      "Epoch 19/100 Iteration 470| Training loss: 2.3854\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 20/100 Iteration 480| Training loss: 2.3378\n",
      "Epoch 20/100 Iteration 490| Training loss: 2.3217\n",
      "Epoch 20/100 Iteration 500| Training loss: 2.3377\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 21/100 Iteration 510| Training loss: 2.2979\n",
      "Epoch 21/100 Iteration 520| Training loss: 2.3572\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 22/100 Iteration 530| Training loss: 2.3000\n",
      "Epoch 22/100 Iteration 540| Training loss: 2.2912\n",
      "Epoch 22/100 Iteration 550| Training loss: 2.3026\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 23/100 Iteration 560| Training loss: 2.2650\n",
      "Epoch 23/100 Iteration 570| Training loss: 2.3256\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 24/100 Iteration 580| Training loss: 2.2677\n",
      "Epoch 24/100 Iteration 590| Training loss: 2.2540\n",
      "Epoch 24/100 Iteration 600| Training loss: 2.2907\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 25/100 Iteration 610| Training loss: 2.2415\n",
      "Epoch 25/100 Iteration 620| Training loss: 2.2892\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 26/100 Iteration 630| Training loss: 2.2523\n",
      "Epoch 26/100 Iteration 640| Training loss: 2.2408\n",
      "Epoch 26/100 Iteration 650| Training loss: 2.2645\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 27/100 Iteration 660| Training loss: 2.2227\n",
      "Epoch 27/100 Iteration 670| Training loss: 2.2800\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 28/100 Iteration 680| Training loss: 2.2285\n",
      "Epoch 28/100 Iteration 690| Training loss: 2.2169\n",
      "Epoch 28/100 Iteration 700| Training loss: 2.2314\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 29/100 Iteration 710| Training loss: 2.1954\n",
      "Epoch 29/100 Iteration 720| Training loss: 2.2453\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 30/100 Iteration 730| Training loss: 2.2070\n",
      "Epoch 30/100 Iteration 740| Training loss: 2.1904\n",
      "Epoch 30/100 Iteration 750| Training loss: 2.2099\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 31/100 Iteration 760| Training loss: 2.1796\n",
      "Epoch 31/100 Iteration 770| Training loss: 2.2304\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 32/100 Iteration 780| Training loss: 2.1748\n",
      "Epoch 32/100 Iteration 790| Training loss: 2.1777\n",
      "Epoch 32/100 Iteration 800| Training loss: 2.1959\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 33/100 Iteration 810| Training loss: 2.1593\n",
      "Epoch 33/100 Iteration 820| Training loss: 2.2090\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 34/100 Iteration 830| Training loss: 2.1583\n",
      "Epoch 34/100 Iteration 840| Training loss: 2.1663\n",
      "Epoch 34/100 Iteration 850| Training loss: 2.1748\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 35/100 Iteration 860| Training loss: 2.1348\n",
      "Epoch 35/100 Iteration 870| Training loss: 2.1872\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 36/100 Iteration 880| Training loss: 2.1455\n",
      "Epoch 36/100 Iteration 890| Training loss: 2.1383\n",
      "Epoch 36/100 Iteration 900| Training loss: 2.1611\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 37/100 Iteration 910| Training loss: 2.1214\n",
      "Epoch 37/100 Iteration 920| Training loss: 2.1727\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 38/100 Iteration 930| Training loss: 2.1272\n",
      "Epoch 38/100 Iteration 940| Training loss: 2.1321\n",
      "Epoch 38/100 Iteration 950| Training loss: 2.1445\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 39/100 Iteration 960| Training loss: 2.1058\n",
      "Epoch 39/100 Iteration 970| Training loss: 2.1557\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 40/100 Iteration 980| Training loss: 2.1120\n",
      "Epoch 40/100 Iteration 990| Training loss: 2.1179\n",
      "Epoch 40/100 Iteration 1000| Training loss: 2.1338\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 41/100 Iteration 1010| Training loss: 2.0952\n",
      "Epoch 41/100 Iteration 1020| Training loss: 2.1396\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 42/100 Iteration 1030| Training loss: 2.0965\n",
      "Epoch 42/100 Iteration 1040| Training loss: 2.1035\n",
      "Epoch 42/100 Iteration 1050| Training loss: 2.1112\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 43/100 Iteration 1060| Training loss: 2.0690\n",
      "Epoch 43/100 Iteration 1070| Training loss: 2.1245\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 44/100 Iteration 1080| Training loss: 2.0834\n",
      "Epoch 44/100 Iteration 1090| Training loss: 2.0943\n",
      "Epoch 44/100 Iteration 1100| Training loss: 2.0969\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 45/100 Iteration 1110| Training loss: 2.0694\n",
      "Epoch 45/100 Iteration 1120| Training loss: 2.1125\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 46/100 Iteration 1130| Training loss: 2.0587\n",
      "Epoch 46/100 Iteration 1140| Training loss: 2.0794\n",
      "Epoch 46/100 Iteration 1150| Training loss: 2.0955\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 47/100 Iteration 1160| Training loss: 2.0529\n",
      "Epoch 47/100 Iteration 1170| Training loss: 2.0989\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 48/100 Iteration 1180| Training loss: 2.0572\n",
      "Epoch 48/100 Iteration 1190| Training loss: 2.0724\n",
      "Epoch 48/100 Iteration 1200| Training loss: 2.0690\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 49/100 Iteration 1210| Training loss: 2.0438\n",
      "Epoch 49/100 Iteration 1220| Training loss: 2.0872\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 50/100 Iteration 1230| Training loss: 2.0417\n",
      "Epoch 50/100 Iteration 1240| Training loss: 2.0524\n",
      "Epoch 50/100 Iteration 1250| Training loss: 2.0705\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 51/100 Iteration 1260| Training loss: 2.0318\n",
      "Epoch 51/100 Iteration 1270| Training loss: 2.0731\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 52/100 Iteration 1280| Training loss: 2.0451\n",
      "Epoch 52/100 Iteration 1290| Training loss: 2.0436\n",
      "Epoch 52/100 Iteration 1300| Training loss: 2.0499\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 53/100 Iteration 1310| Training loss: 2.0257\n",
      "Epoch 53/100 Iteration 1320| Training loss: 2.0563\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 54/100 Iteration 1330| Training loss: 2.0235\n",
      "Epoch 54/100 Iteration 1340| Training loss: 2.0330\n",
      "Epoch 54/100 Iteration 1350| Training loss: 2.0332\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 55/100 Iteration 1360| Training loss: 2.0123\n",
      "Epoch 55/100 Iteration 1370| Training loss: 2.0480\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 56/100 Iteration 1380| Training loss: 2.0090\n",
      "Epoch 56/100 Iteration 1390| Training loss: 2.0200\n",
      "Epoch 56/100 Iteration 1400| Training loss: 2.0246\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 57/100 Iteration 1410| Training loss: 1.9978\n",
      "Epoch 57/100 Iteration 1420| Training loss: 2.0412\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 58/100 Iteration 1430| Training loss: 1.9972\n",
      "Epoch 58/100 Iteration 1440| Training loss: 2.0199\n",
      "Epoch 58/100 Iteration 1450| Training loss: 2.0164\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 59/100 Iteration 1460| Training loss: 1.9794\n",
      "Epoch 59/100 Iteration 1470| Training loss: 2.0274\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 60/100 Iteration 1480| Training loss: 1.9873\n",
      "Epoch 60/100 Iteration 1490| Training loss: 2.0040\n",
      "Epoch 60/100 Iteration 1500| Training loss: 2.0033\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 61/100 Iteration 1510| Training loss: 1.9842\n",
      "Epoch 61/100 Iteration 1520| Training loss: 2.0320\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 62/100 Iteration 1530| Training loss: 1.9851\n",
      "Epoch 62/100 Iteration 1540| Training loss: 1.9965\n",
      "Epoch 62/100 Iteration 1550| Training loss: 1.9930\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 63/100 Iteration 1560| Training loss: 1.9664\n",
      "Epoch 63/100 Iteration 1570| Training loss: 2.0154\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 64/100 Iteration 1580| Training loss: 1.9748\n",
      "Epoch 64/100 Iteration 1590| Training loss: 1.9873\n",
      "Epoch 64/100 Iteration 1600| Training loss: 1.9807\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 65/100 Iteration 1610| Training loss: 1.9672\n",
      "Epoch 65/100 Iteration 1620| Training loss: 2.0087\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 66/100 Iteration 1630| Training loss: 1.9665\n",
      "Epoch 66/100 Iteration 1640| Training loss: 1.9842\n",
      "Epoch 66/100 Iteration 1650| Training loss: 1.9893\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 67/100 Iteration 1660| Training loss: 1.9504\n",
      "Epoch 67/100 Iteration 1670| Training loss: 1.9915\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 68/100 Iteration 1680| Training loss: 1.9580\n",
      "Epoch 68/100 Iteration 1690| Training loss: 1.9751\n",
      "Epoch 68/100 Iteration 1700| Training loss: 1.9620\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 69/100 Iteration 1710| Training loss: 1.9460\n",
      "Epoch 69/100 Iteration 1720| Training loss: 1.9900\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 70/100 Iteration 1730| Training loss: 1.9508\n",
      "Epoch 70/100 Iteration 1740| Training loss: 1.9586\n",
      "Epoch 70/100 Iteration 1750| Training loss: 1.9620\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 71/100 Iteration 1760| Training loss: 1.9336\n",
      "Epoch 71/100 Iteration 1770| Training loss: 1.9852\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 72/100 Iteration 1780| Training loss: 1.9447\n",
      "Epoch 72/100 Iteration 1790| Training loss: 1.9588\n",
      "Epoch 72/100 Iteration 1800| Training loss: 1.9536\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 73/100 Iteration 1810| Training loss: 1.9253\n",
      "Epoch 73/100 Iteration 1820| Training loss: 1.9709\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 74/100 Iteration 1830| Training loss: 1.9380\n",
      "Epoch 74/100 Iteration 1840| Training loss: 1.9511\n",
      "Epoch 74/100 Iteration 1850| Training loss: 1.9474\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 75/100 Iteration 1860| Training loss: 1.9215\n",
      "Epoch 75/100 Iteration 1870| Training loss: 1.9722\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 76/100 Iteration 1880| Training loss: 1.9178\n",
      "Epoch 76/100 Iteration 1890| Training loss: 1.9416\n",
      "Epoch 76/100 Iteration 1900| Training loss: 1.9377\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 77/100 Iteration 1910| Training loss: 1.9150\n",
      "Epoch 77/100 Iteration 1920| Training loss: 1.9551\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 78/100 Iteration 1930| Training loss: 1.9204\n",
      "Epoch 78/100 Iteration 1940| Training loss: 1.9321\n",
      "Epoch 78/100 Iteration 1950| Training loss: 1.9277\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 79/100 Iteration 1960| Training loss: 1.9079\n",
      "Epoch 79/100 Iteration 1970| Training loss: 1.9474\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 80/100 Iteration 1980| Training loss: 1.9189\n",
      "Epoch 80/100 Iteration 1990| Training loss: 1.9282\n",
      "Epoch 80/100 Iteration 2000| Training loss: 1.9225\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 81/100 Iteration 2010| Training loss: 1.9045\n",
      "Epoch 81/100 Iteration 2020| Training loss: 1.9485\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 82/100 Iteration 2030| Training loss: 1.9105\n",
      "Epoch 82/100 Iteration 2040| Training loss: 1.9177\n",
      "Epoch 82/100 Iteration 2050| Training loss: 1.9232\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 83/100 Iteration 2060| Training loss: 1.8908\n",
      "Epoch 83/100 Iteration 2070| Training loss: 1.9423\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 84/100 Iteration 2080| Training loss: 1.9082\n",
      "Epoch 84/100 Iteration 2090| Training loss: 1.9266\n",
      "Epoch 84/100 Iteration 2100| Training loss: 1.9182\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 85/100 Iteration 2110| Training loss: 1.8889\n",
      "Epoch 85/100 Iteration 2120| Training loss: 1.9332\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 86/100 Iteration 2130| Training loss: 1.8902\n",
      "Epoch 86/100 Iteration 2140| Training loss: 1.9162\n",
      "Epoch 86/100 Iteration 2150| Training loss: 1.9127\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 87/100 Iteration 2160| Training loss: 1.8895\n",
      "Epoch 87/100 Iteration 2170| Training loss: 1.9338\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 88/100 Iteration 2180| Training loss: 1.8880\n",
      "Epoch 88/100 Iteration 2190| Training loss: 1.9095\n",
      "Epoch 88/100 Iteration 2200| Training loss: 1.8950\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 89/100 Iteration 2210| Training loss: 1.8715\n",
      "Epoch 89/100 Iteration 2220| Training loss: 1.9141\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 90/100 Iteration 2230| Training loss: 1.8920\n",
      "Epoch 90/100 Iteration 2240| Training loss: 1.9013\n",
      "Epoch 90/100 Iteration 2250| Training loss: 1.9038\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 91/100 Iteration 2260| Training loss: 1.8801\n",
      "Epoch 91/100 Iteration 2270| Training loss: 1.9049\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 92/100 Iteration 2280| Training loss: 1.8632\n",
      "Epoch 92/100 Iteration 2290| Training loss: 1.8911\n",
      "Epoch 92/100 Iteration 2300| Training loss: 1.8878\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 93/100 Iteration 2310| Training loss: 1.8629\n",
      "Epoch 93/100 Iteration 2320| Training loss: 1.8978\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 94/100 Iteration 2330| Training loss: 1.8679\n",
      "Epoch 94/100 Iteration 2340| Training loss: 1.8877\n",
      "Epoch 94/100 Iteration 2350| Training loss: 1.8697\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 95/100 Iteration 2360| Training loss: 1.8589\n",
      "Epoch 95/100 Iteration 2370| Training loss: 1.9014\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 96/100 Iteration 2380| Training loss: 1.8649\n",
      "Epoch 96/100 Iteration 2390| Training loss: 1.8888\n",
      "Epoch 96/100 Iteration 2400| Training loss: 1.8813\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 97/100 Iteration 2410| Training loss: 1.8584\n",
      "Epoch 97/100 Iteration 2420| Training loss: 1.8886\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 98/100 Iteration 2430| Training loss: 1.8575\n",
      "Epoch 98/100 Iteration 2440| Training loss: 1.8739\n",
      "Epoch 98/100 Iteration 2450| Training loss: 1.8674\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 99/100 Iteration 2460| Training loss: 1.8427\n",
      "Epoch 99/100 Iteration 2470| Training loss: 1.9003\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n",
      "Epoch 100/100 Iteration 2480| Training loss: 1.8480\n",
      "Epoch 100/100 Iteration 2490| Training loss: 1.8710\n",
      "Epoch 100/100 Iteration 2500| Training loss: 1.8583\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.meta\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:./model-100/language_modeling.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1500\n"
     ]
    }
   ],
   "source": [
    "# Create and train CharRNN Model\n",
    "batch_size = 64\n",
    "num_steps = 100\n",
    "train_x, train_y = reshape_data(text_ints,\n",
    "                                batch_size,\n",
    "                                num_steps)\n",
    "\n",
    "rnn = CharRNN(num_classes=len(chars), batch_size=batch_size)\n",
    "rnn.train(train_x, train_y,\n",
    "            num_epochs=100,\n",
    "            ckpt_dir='./model-100/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yr/41cc5dm96jxdwsjd0d6n6yhw0000gn/T/ipykernel_2045/143551028.py:67: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  tf.compat.v1.nn.rnn_cell.BasicLSTMCell(self.lstm_size),\n",
      "/var/folders/yr/41cc5dm96jxdwsjd0d6n6yhw0000gn/T/ipykernel_2045/143551028.py:87: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  logits = tf.layers.dense(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  << lstm_outputs  >> Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 128), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from ./model-100/language_modeling.ckpt\n",
      "The wirle of the mise, whot' wise and sertor and my that wist of the murse, bus best the thas to the sind and the mint sheath, wotle some haues ant to me a makned\n",
      "\n",
      "   Ham. No mo harke this tast is tiliue, aroue,\n",
      "Tees thes theere and and tor his, on to heare\n",
      "\n",
      "   Ham. I sand yor sies alaie, oue to hath as, and we mes ant her,\n",
      "Ber it\n",
      "the Sinder our sendes of my mere\n",
      "\n",
      "   Ham. Whe is the why do sint in the worla beane:\n",
      "I sare you hous singent, in him of in tho gaue\n",
      "\n",
      "   Ham. I swore, and tere thee if hor m\n"
     ]
    }
   ],
   "source": [
    "# CharRNN Model in Sampling Mode\n",
    "# Specify that sampling=True\n",
    "del rnn\n",
    "\n",
    "np.random.seed(123)\n",
    "rnn = CharRNN(len(chars), sampling=True)\n",
    "print(rnn.sample(ckpt_dir='./model-100/',\n",
    "                        output_length=500))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "083a42570bcc9540ccea0c06ed31349ced70ab63bde88af92c61b348c069bb97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
